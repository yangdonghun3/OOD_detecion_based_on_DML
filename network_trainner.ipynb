{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST, MNIST\n",
    "from torchvision.datasets import SVHN, CIFAR10, CIFAR100\n",
    "from torchvision import transforms\n",
    "from utils.datasets import SiameseDataset, TripletDataset, CrossEntropyDataset\n",
    "import models.resnet, models.siamesenet, models.triplenet, models.resnet_sis\n",
    "from utils.losses import ContrastiveLoss, TripletLoss\n",
    "from utils.trainer import fit\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "epoch=100\n",
    "lr=0.001\n",
    "batch_size=32\n",
    "\n",
    "# Configuration\n",
    "input_data = ['fashionmnist', 'mnist']\n",
    "model_list = [ 'siam', 'baseline','triplet']\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}\n",
    "warnings.filterwarnings(action='ignore') # warning message off\n",
    "which_resnet = models.resnet.ResNet34\n",
    "\n",
    "\n",
    "class DataConfig():\n",
    "    def __init__(self, data_name):\n",
    "        if data_name == 'fashionmnist':\n",
    "            self.mean, self.std = (0.28604059698879553,), (0.35302424451492237,)\n",
    "            self.path = '../data/FashionMNIST'\n",
    "            self.dataset_f = FashionMNIST\n",
    "            \n",
    "        elif data_name == 'mnist':\n",
    "            self.mean, self.std = (0.1307,), (0.3081,)\n",
    "            self.path = '../data/MNIST'\n",
    "            self.dataset_f = MNIST\n",
    "            \n",
    "        elif data_name == 'svhn':\n",
    "            self.mean, self.std = [0.4380, 0.4440, 0.4730], [0.1751, 0.1771, 0.1744]\n",
    "            self.path = '../data/SVHN'\n",
    "            self.dataset_f = SVHN\n",
    "            \n",
    "        elif data_name == 'cifar10':\n",
    "            self.mean, self.std = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "            self.path = '../data/CIFAR10'\n",
    "            self.dataset_f = CIFAR10\n",
    "\n",
    "        elif data_name == 'cifar100':\n",
    "            self.mean, self.std = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "            self.path = '../data/CIFAR100'\n",
    "            self.dataset_f = CIFAR100\n",
    "            \n",
    "        self.train_dataset = self.data_init(True)\n",
    "        self.test_dataset = self.data_init(False)\n",
    "            \n",
    "    def data_init(self, train_opt):\n",
    "        return self.dataset_f(self.path, \n",
    "                                        train=train_opt, \n",
    "                                        download=True, \n",
    "                                        transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                             transforms.Normalize(self.mean, self.std)]\n",
    "                                        ))\n",
    "\n",
    "            \n",
    "class ModelConfig():\n",
    "    def __init__(self, model_name):\n",
    "        if model_name == 'siam':\n",
    "            self.dataset_for_model = SiameseDataset\n",
    "            self.model = models.siamesenet.SiameseNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = ContrastiveLoss(self.margin)\n",
    "            self.model_flag = True\n",
    "            \n",
    "        elif model_name == 'triplet':\n",
    "            self.dataset_for_model = TripletDataset\n",
    "            self.model = models.triplenet.TripletNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = TripletLoss(self.margin)\n",
    "            self.model_flag = True\n",
    "            \n",
    "        elif model_name == 'baseline' or model_name == 'odin':\n",
    "            self.dataset_for_model = CrossEntropyDataset\n",
    "            self.model = models.resnet_sis.ResNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = nn.CrossEntropyLoss()\n",
    "            self.model_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Excution (each data, each model)\n",
    "for data_name in input_data:\n",
    "    print(epoch)\n",
    "    print(lr)\n",
    "    # creating dataset\n",
    "    dc = DataConfig(data_name)\n",
    "    num_of_channel = len(dc.mean)\n",
    "    try:\n",
    "        num_of_classes = len(set(dc.train_dataset.labels))\n",
    "    except AttributeError:\n",
    "        try :\n",
    "            num_of_classes = len(set(dc.train_dataset.train_labels))\n",
    "        except AttributeError:\n",
    "            num_of_classes = len(set(dc.train_dataset.classes))\n",
    "    for model_name in model_list:\n",
    "        mc = ModelConfig(model_name)\n",
    "\n",
    "        # creating data loader\n",
    "        train_dataset = mc.dataset_for_model(dc.train_dataset) \n",
    "        test_dataset = mc.dataset_for_model(dc.test_dataset)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=mc.batch_size, shuffle=True, **kwargs)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=mc.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "        # training model\n",
    "        embedding_resnet = which_resnet(input_channels=num_of_channel, num_c=num_of_classes, model_flag=mc.model_flag)\n",
    "        model = mc.model(embedding_resnet)\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=mc.lr)\n",
    "\n",
    "        print(f\"[{datetime.now()}] {model_name}_resnet_{data_name} Training Start\")\n",
    "        model_nname = model_name + '_resnet_' + data_name\n",
    "        fit(train_loader, test_loader, model, mc.loss_f, optimizer, mc.n_epochs, cuda, mc.log_interval, model_nname=model_nname, model_flag=mc.model_flag)\n",
    "        torch.save(model, 'trained_models/'+ model_nname + '.pth')\n",
    "        print(f\"[{datetime.now()}] {model_name}_resnet_{data_name} Training End\", end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood_ysk",
   "language": "python",
   "name": "ood_ysk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
